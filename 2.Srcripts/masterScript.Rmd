---
title: "Scripts for Higiene Project"
author: "Flores-Kanter PE"
output:
  pdf_document:
    toc: yes
  html_document:
    code_folding: show
    theme: paper
    highlight: pygments
    toc: yes
---

```{r}
if(!"devtools" %in% row.names(installed.packages())){
  install.packages("devtools")
}
devtools::install_github("AlexChristensen/SemNeT")

library(stringi)
library(stringr)
library(qdap)
library(NLP)
library(tm)
library(SemNeT)
library(NetworkToolbox)
library(tidyverse)
```


#Data Processing Script

```{r}

text.df<-read.csv("txt_jovenes.csv", sep = ";", header = TRUE) #Cambiar bases de acuerdo a los objetivos. "txt_viejos.csv"
grp<-read.csv("group_jovenes.csv", sep = ";", header = TRUE) #Cambiar bases de acuerdo a los objetivos. "group_viejos.csv"

#The first function is a wrapper for the base R tolower function.

# Return NA instead of tolower error
tryTolower <- function(x){
# return NA when there is an error
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error = function(e) e)
# if not an error
if (!inherits(try_error, 'error'))
y = tolower(x)
return(y)
}

#Next you will define our stopwords.
custom.stopwords <- stopwords('spanish')


#Next you will include the new tryTolower function as part of a larger preprocessing function. Here you create a function called clean.corpus.
clean.corpus<-function(corpus){
corpus <- tm_map(corpus,
content_transformer(tryTolower))
corpus <- tm_map(corpus, removeWords,
custom.stopwords)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
return(corpus)
}

#Before applying these cleaning functions, you need to define the tweets object as your corpus or collection of natural language documents. Additionally you are preserving the metadata about each document.
tweets<-data.frame(doc_id=seq(1:nrow(text.df)),text=text.df$Texto)

corpus <- VCorpus(DataframeSource(tweets))

#With all the preprocessing transformation functions organized you must now apply them to the DeltaAssist corpus.
corpus<-clean.corpus(corpus)

#Frequent Terms and Associations
#First, you create a new object called tdm, which is a list object used by the tm package.
tdm<-TermDocumentMatrix(corpus,control=list(weighting=weightTf))
tdm.tweets.m<-as.matrix(tdm)



## EGAnet (Golino)
corpus.stem <- tm_map(corpus, stemDocument)
dtm <- DocumentTermMatrix(corpus.stem)
dtm.sparsity.rm <- removeSparseTerms(dtm, 0.90)

dtm.data <- as.data.frame(as.matrix(dtm.sparsity.rm))
head(dtm.data)
colnames(dtm.data)


##SemNet (Christensen)

Abinar <- binarize(dtm.data)

## Change column names (variable names)
colnames(grp) <- c("conditions","times")


# Attach 'Group' variable to the binary response matrix
behav <- cbind(grp, Abinar)

#write.csv(behav, "binaryResponse_jovenes.csv", row.names = FALSE)
#write.csv(behav, "binaryResponse_viejos.csv", row.names = FALSE)

# Create groups response matrices

sinHigiene_e1 <-behav %>% 
  filter(conditions=="sinhigiene" & times=="E1") %>% 
select(-c("conditions","times"))

sinHigiene_e2 <-behav %>% 
  filter(conditions=="sinhigiene" & times=="E2") %>% 
select(-c("conditions","times"))

sinHigiene_t1 <-behav %>% 
  filter(conditions=="sinhigiene" & times=="T1") %>% 
select(-c("conditions","times"))

sinHigiene_t2 <-behav %>% 
  filter(conditions=="sinhigiene" & times=="T2") %>% 
select(-c("conditions","times"))

conHigiene_e1 <-behav %>% 
  filter(conditions=="conhigiene" & times=="E1") %>% 
select(-c("conditions","times"))

conHigiene_e2 <-behav %>% 
  filter(conditions=="conhigiene" & times=="E2") %>% 
select(-c("conditions","times"))

conHigiene_t1 <-behav %>% 
  filter(conditions=="conhigiene" & times=="T1") %>% 
select(-c("conditions","times"))

conHigiene_t2 <-behav %>% 
  filter(conditions=="conhigiene" & times=="T2") %>% 
select(-c("conditions","times"))


```

#Data Analysis Script

```{r}

#---------------------------#
# 2.1.2. Network estimation #
#---------------------------#

## TMFG

### Finalize matrices so that each response has been given by at least two participants
final.sh.e1 <- finalize(sinHigiene_e1, minCase = 2)
final.sh.t1 <- finalize(sinHigiene_t1, minCase = 2)
final.sh.e2 <- finalize(sinHigiene_e2, minCase = 2)
final.sh.t2 <- finalize(sinHigiene_t2, minCase = 2)
final.ch.e1 <- finalize(conHigiene_e1, minCase = 2)
final.ch.t1 <- finalize(conHigiene_t1, minCase = 2)
final.ch.e2 <- finalize(conHigiene_e2, minCase = 2)
final.ch.t2 <- finalize(conHigiene_t2, minCase = 2)

###
### Equate the responses across the networks
eq <- equate(final.sh.e1, final.sh.t1, final.sh.e2, final.sh.t2, final.ch.e1, final.ch.t1, final.ch.e2, final.ch.t2)

equate.sh.e1 <- eq$final.sh.e1
equate.sh.t1 <- eq$final.sh.t1
equate.sh.e2 <- eq$final.sh.e2
equate.sh.t2 <- eq$final.sh.t2
equate.ch.e1 <- eq$final.ch.e1
equate.ch.t1 <- eq$final.ch.t1
equate.ch.e2 <- eq$final.ch.e2
equate.ch.t2 <- eq$final.ch.t2


### Compute cosine similarity for equated binary response matrices
cosine.sh.e1 <- similarity(equate.sh.e1, method = "cosine")
cosine.sh.t1 <- similarity(equate.sh.t1, method = "cosine")
cosine.sh.e2 <- similarity(equate.sh.e2, method = "cosine")
cosine.sh.t2 <- similarity(equate.sh.t2, method = "cosine")
cosine.ch.e1 <- similarity(equate.ch.e1, method = "cosine")
cosine.ch.t1 <- similarity(equate.ch.t1, method = "cosine")
cosine.ch.e2 <- similarity(equate.ch.e2, method = "cosine")
cosine.ch.t2 <- similarity(equate.ch.t2, method = "cosine")

###
### Estimate networks

net.sh.e1 <- TMFG(cosine.sh.e1)
net.sh.t1 <- TMFG(cosine.sh.t1)
net.sh.e2 <- TMFG(cosine.sh.e2)
net.sh.t2 <- TMFG(cosine.sh.t2)
net.ch.e1 <- TMFG(cosine.ch.e1)
net.ch.t1 <- TMFG(cosine.ch.t1)
net.ch.e2 <- TMFG(cosine.ch.e2)
net.ch.t2 <- TMFG(cosine.ch.t2)


## Visualize networks

net.sh.e1.binar <- binarize(net.sh.e1$A)
net.sh.t1.binar <- binarize(net.sh.t1$A)
net.sh.e2.binar <- binarize(net.sh.e2$A)
net.sh.t2.binar <- binarize(net.sh.t2$A)
net.ch.e1.binar <- binarize(net.ch.e1$A)
net.ch.t1.binar <- binarize(net.ch.t1$A)
net.ch.e2.binar <- binarize(net.ch.e2$A)
net.ch.t2.binar <- binarize(net.ch.t2$A)


compare_nets(net.sh.e1.binar, net.sh.t1.binar, net.sh.e2.binar, net.sh.t2.binar,
             net.ch.e1.binar, net.ch.t1.binar, net.ch.e2.binar, net.ch.t2.binar,
  title = list(
    "Sin Higiene/E1",  "Sin Higiene/T1",
    "Sin Higiene/E2",  "Sin Higiene/T2",
    "Con Higiene/E1",  "Con Higiene/T1",
    "Con Higiene/E2",  "Con Higiene/T2"
  )
)




##################################
## 3.2. Global Network Measures ##
##################################

# Compute network measures
# semnetmeas(netjt1_binar, meas = c("ASPL", "CC", "Q"), weighted = FALSE)
# semnetmeas(netjt2_binar, meas = c("ASPL", "CC", "Q"), weighted = FALSE)
# semnetmeas(netvt1_binar, meas = c("ASPL", "CC", "Q"), weighted = FALSE)
# semnetmeas(netvt2_binar, meas = c("ASPL", "CC", "Q"), weighted = FALSE)




############################
## 3.3. Statistical Tests ##
############################

#----------------------------------------#
# 3.3.2. Bootstrapped case-wise networks #
#----------------------------------------#


## Perform bootstrap networks

boot <- bootSemNeT(sinHigiene_e1, sinHigiene_t1, sinHigiene_e2, sinHigiene_t2,
                   conHigiene_e1, conHigiene_t1, conHigiene_e2, conHigiene_t2,
  type = "case", method = "TMFG", sim = "cosine",
  cores = 7, iter = 1000)



## Compute tests
results <- test.bootSemNeT(
  boot,
  test = "ANCOVA",
  formula = "y ~ conditions*times",
  groups = grp
)



# ASPL
Aspl<- results$fullResults$Case$ASPL$ANCOVA
results$fullResults$Case$ASPL$adjustedMeans
results$fullResults$Case$ASPL$HSD



# CC
CC<- results$fullResults$Case$CC$ANCOVA
results$fullResults$Case$CC$adjustedMeans
results$fullResults$Case$CC$HSD



# Q
Q<- results$fullResults$Case$Q$ANCOVA
results$fullResults$Case$Q$adjustedMeans
results$fullResults$Case$Q$HSD




#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

# Plot Bootstrap ----

## Plot bootstrap


plot(
  boot,
   groups = c(
    "Sin Higiene/E1",  "Sin Higiene/T1",
    "Sin Higiene/E2",  "Sin Higiene/T2",
    "Con Higiene/E1",  "Con Higiene/T1",
    "Con Higiene/E2",  "Con Higiene/T2"
     )
    )
  
#plots <-   plot(
 # boot,
  #groups = c(
  #  "Jovenes/Time 1", "Adultos/Time 1", "Viejos/Time 1",
  #  "Jovenes/Time 2", "Adultos/Time 2", "Viejos/Time 2"
  #)
#)


```

